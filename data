# NAIVE BAYES 
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
X, y = load_iris(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)
model = GaussianNB()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred) * 100, "%")


#SVM
from sklearn import svm, datasets
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import numpy as np
X, y = datasets.load_iris(return_X_y=True)
X = X[:, :2]  # Select only Sepal Length & Sepal Width
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)
model = svm.SVC(kernel="linear", C=1)
model.fit(X_train, y_train)
print("Accuracy:", accuracy_score(y_test, model.predict(X_test)) * 100, "%")
xx, yy = np.meshgrid(np.linspace(X[:, 0].min()-1, X[:, 0].max()+1, 100),
                     np.linspace(X[:, 1].min()-1, X[:, 1].max()+1, 100))
Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)
plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.coolwarm)
plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm)
plt.xlabel('Sepal Length')
plt.ylabel('Sepal Width')
plt.title("SVM Classification")
plt.show()

#K-MEANS
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.cluster import KMeans
X = pd.read_csv('Mall_Customers.csv').iloc[:, [3, 4]].values
wcss = [KMeans(n_clusters=i, init='k-means++', random_state=42).fit(X).inertia_ for i in range(1, 11)]
plt.plot(range(1, 11), wcss, marker='o')
plt.title('Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS')
plt.show()
kmeans = KMeans(n_clusters=5, init='k-means++', random_state=42).fit(X)
for i in range(5):
    plt.scatter(X[kmeans.labels_ == i, 0], X[kmeans.labels_ == i, 1], label=f'Cluster {i+1}')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, c='yellow', marker='X', label='Centroids')
plt.title('Customer Segmentation')
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.legend()
plt.show()

#HIERARCHICAL CLUSTERING
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import scipy.cluster.hierarchy as shc
from sklearn.cluster import AgglomerativeClustering
X = pd.read_csv("Mall_Customers.csv").iloc[:, [3, 4]].values
shc.dendrogram(shc.linkage(X, method="ward"))
plt.title("Dendrogram")
plt.xlabel("Customers")
plt.ylabel("Distance")
plt.show()
clusters = AgglomerativeClustering(n_clusters=5, linkage="ward").fit_predict(X)
colors = ['blue', 'green', 'red', 'cyan', 'magenta']
for i in range(5):
    plt.scatter(X[clusters == i, 0], X[clusters == i, 1], s=100, c=colors[i], label=f'Cluster {i+1}')
plt.title("Customer Segments")
plt.xlabel("Annual Income (k$)")
plt.ylabel("Spending Score (1-100)")
plt.legend()
plt.show()


#DATA ANALYSIS
import pandas as pd
import matplotlib.pyplot as plt
subjects = ['Math', 'English', 'History', 'Chem', 'Geo', 'Physics', 'Bio', 'CS']
stress = [9, 3, 5, 1, 8, 5, 10, 2]
grades = [15, 10, 7, 8, 11, 8, 17, 20]
df = pd.DataFrame({'Subject': subjects, 'Stress': stress, 'Grade': grades})
ax = plt.gca()
df.plot(x='Subject', y='Stress', marker='o', color='red', ax=ax, label='Stress')
df.plot(x='Subject', y='Grade', marker='s', color='blue', ax=ax, label='Grade')
plt.xlabel("Subjects")
plt.ylabel("Values")
plt.title("Stress and Grades per Subject")
plt.show()


#LINEAR REGRESSION
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
data = pd.read_csv("salary_data.csv")
X, y = data.iloc[:, :-1].values, data.iloc[:, -1].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=0)
model = LinearRegression().fit(X_train, y_train)
plt.scatter(X_train, y_train, color="green")
plt.plot(X_train, model.predict(X_train), color="red")
plt.title("Salary vs Experience (Training)")
plt.xlabel("Years of Experience")
plt.ylabel("Salary")
plt.show()
plt.scatter(X_test, y_test, color="blue")
plt.plot(X_train, model.predict(X_train), color="red")
plt.title("Salary vs Experience (Test)")
plt.xlabel("Years of Experience")
plt.ylabel("Salary")
plt.show()



