
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score

# Load dataset
X, y = load_iris(return_X_y=True)

# Split into training and testing sets (60% train, 40% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)

# Train the model
model = GaussianNB()
model.fit(X_train, y_train)

# Predict and evaluate
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred) * 100, "%")


from sklearn import svm, datasets
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import numpy as np

# Load dataset (only first two features)
X, y = datasets.load_iris(return_X_y=True)
X = X[:, :2]  # Select only Sepal Length & Sepal Width

# Split data into training & testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

# Train SVM model
model = svm.SVC(kernel="linear", C=1)
model.fit(X_train, y_train)

# Print accuracy
print("Accuracy:", accuracy_score(y_test, model.predict(X_test)) * 100, "%")

# Plot decision boundary
xx, yy = np.meshgrid(np.linspace(X[:, 0].min()-1, X[:, 0].max()+1, 100),
                     np.linspace(X[:, 1].min()-1, X[:, 1].max()+1, 100))

Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)

plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.coolwarm)
plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm)
plt.xlabel('Sepal Length')
plt.ylabel('Sepal Width')
plt.title("SVM Classification")
plt.show()


import matplotlib.pyplot as plt
import pandas as pd
from sklearn.cluster import KMeans

# Load dataset (Annual Income vs Spending Score)
X = pd.read_csv('Mall_Customers.csv').iloc[:, [3, 4]].values

# Elbow Method to find optimal clusters
wcss = [KMeans(n_clusters=i, init='k-means++', random_state=42).fit(X).inertia_ for i in range(1, 11)]
plt.plot(range(1, 11), wcss, marker='o')
plt.title('Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS')
plt.show()

# Apply K-Means with 5 clusters
kmeans = KMeans(n_clusters=5, init='k-means++', random_state=42).fit(X)

# Plot Clusters
for i in range(5):
    plt.scatter(X[kmeans.labels_ == i, 0], X[kmeans.labels_ == i, 1], label=f'Cluster {i+1}')

# Plot Centroids
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, c='yellow', marker='X', label='Centroids')
plt.title('Customer Segmentation')
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.legend()
plt.show()


import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import scipy.cluster.hierarchy as shc
from sklearn.cluster import AgglomerativeClustering

# Load dataset and select relevant columns
X = pd.read_csv("Mall_Customers.csv").iloc[:, [3, 4]].values

# Plot dendrogram to determine the optimal number of clusters
shc.dendrogram(shc.linkage(X, method="ward"))
plt.title("Dendrogram")
plt.xlabel("Customers")
plt.ylabel("Distance")
plt.show()

# Apply hierarchical clustering
clusters = AgglomerativeClustering(n_clusters=5, linkage="ward").fit_predict(X)

# Plot clustered data
colors = ['blue', 'green', 'red', 'cyan', 'magenta']
for i in range(5):
    plt.scatter(X[clusters == i, 0], X[clusters == i, 1], s=100, c=colors[i], label=f'Cluster {i+1}')

plt.title("Customer Segments")
plt.xlabel("Annual Income (k$)")
plt.ylabel("Spending Score (1-100)")
plt.legend()
plt.show()



import pandas as pd
import matplotlib.pyplot as plt

# Data
subjects = ['Math', 'English', 'History', 'Chem', 'Geo', 'Physics', 'Bio', 'CS']
stress = [9, 3, 5, 1, 8, 5, 10, 2]
grades = [15, 10, 7, 8, 11, 8, 17, 20]

# Create DataFrame
df = pd.DataFrame({'Subject': subjects, 'Stress': stress, 'Grade': grades})

# Create plot
ax = plt.gca()
df.plot(x='Subject', y='Stress', marker='o', color='red', ax=ax, label='Stress')
df.plot(x='Subject', y='Grade', marker='s', color='blue', ax=ax, label='Grade')

# Labels and display
plt.xlabel("Subjects")
plt.ylabel("Values")
plt.title("Stress and Grades per Subject")
plt.show()



